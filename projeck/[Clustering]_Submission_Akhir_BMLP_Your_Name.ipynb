{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZLRMFl0JyyQ"
   },
   "source": [
    "# **1. Perkenalan Dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8fTgOvMMzcp"
   },
   "outputs": [],
   "source": [
    "# git clone https://github.com/marceloreis/HTI.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tahap Pertama: Mencari dan Menggunakan Dataset Tanpa Label\n",
    "\n",
    "### 1. Sumber Dataset\n",
    "Dataset dapat diperoleh dari berbagai sumber, seperti public repositories atau data primer yang Anda kumpulkan sendiri. Contoh sumber dataset:\n",
    "- [GitHub repo: marceloreis/HTI](https://github.com/marceloreis/HTI.git)\n",
    "\n",
    "### 2. Ketentuan Dataset\n",
    "Dataset harus tanpa label, memiliki minimal 1000 baris, dan mengandung data kategorikal serta numerikal.\n",
    "\n",
    "### 3. Pembatasan\n",
    "Dataset yang sudah digunakan dalam latihan clustering (seperti customer segmentation) tidak boleh digunakan.\n",
    "\n",
    "---\n",
    "\n",
    "### Contoh Dataset\n",
    "\n",
    "- **Jumlah Baris**: 420,768\n",
    "- **Jumlah Kolom**: 18\n",
    "\n",
    "#### Jenis Data di Setiap Kolom:\n",
    "| Kolom       | Tipe Data |\n",
    "|-------------|-----------|\n",
    "| `No`        | int64     |\n",
    "| `year`      | int64     |\n",
    "| `month`     | int64     |\n",
    "| `day`       | int64     |\n",
    "| `hour`      | int64     |\n",
    "| `PM2.5`     | float64   |\n",
    "| `PM10`      | float64   |\n",
    "| `SO2`       | float64   |\n",
    "| `NO2`       | float64   |\n",
    "| `CO`        | float64   |\n",
    "| `O3`        | float64   |\n",
    "| `TEMP`      | float64   |\n",
    "| `PRES`      | float64   |\n",
    "| `DEWP`      | float64   |\n",
    "| `RAIN`      | float64   |\n",
    "| `wd`        | object    |\n",
    "| `WSPM`      | float64   |\n",
    "| `station`   | object    |\n",
    "\n",
    "#### Kolom Numerikal:\n",
    "- `No`, `year`, `month`, `day`, `hour`, `PM2.5`, `PM10`, `SO2`, `NO2`, `CO`, `O3`, `TEMP`, `PRES`, `DEWP`, `RAIN`, `WSPM`\n",
    "\n",
    "#### Kolom Kategorikal:\n",
    "- `wd`, `station`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKADPWcFKlj3"
   },
   "source": [
    "# **2. Import Library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BlmvjLY9M4Yj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3YIEnAFKrKL"
   },
   "source": [
    "# **3. Memuat Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ey3ItwTen_7E"
   },
   "source": [
    "Pada tahap ini, Anda perlu memuat dataset ke dalam notebook. Jika dataset dalam format CSV, Anda bisa menggunakan pustaka pandas untuk membacanya. Pastikan untuk mengecek beberapa baris awal dataset untuk memahami strukturnya dan memastikan data telah dimuat dengan benar.\n",
    "\n",
    "Jika dataset berada di Google Drive, pastikan Anda menghubungkan Google Drive ke Colab terlebih dahulu. Setelah dataset berhasil dimuat, langkah berikutnya adalah memeriksa kesesuaian data dan siap untuk dianalisis lebih lanjut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHCGNTyrM5fS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Direktori tempat file CSV berada\n",
    "data_dir = 'projeck/data'\n",
    "\n",
    "# List untuk menyimpan DataFrame\n",
    "df_list = []\n",
    "\n",
    "# Daftar nama file CSV yang akan dibaca\n",
    "csv_files = [\n",
    "    'PRSA_Data_Aotizhongxin_20130301-20170228.csv',\n",
    "    'PRSA_Data_Changping_20130301-20170228.csv',\n",
    "    'PRSA_Data_Dingling_20130301-20170228.csv',\n",
    "    'PRSA_Data_Dongsi_20130301-20170228.csv',\n",
    "    'PRSA_Data_Guanyuan_20130301-20170228.csv',\n",
    "    'PRSA_Data_Gucheng_20130301-20170228.csv',\n",
    "    'PRSA_Data_Huairou_20130301-20170228.csv',\n",
    "    'PRSA_Data_Nongzhanguan_20130301-20170228.csv',\n",
    "    'PRSA_Data_Shunyi_20130301-20170228.csv',\n",
    "    'PRSA_Data_Tiantan_20130301-20170228.csv',\n",
    "    'PRSA_Data_Wanliu_20130301-20170228.csv',\n",
    "    'PRSA_Data_Wanshouxigong_20130301-20170228.csv'\n",
    "]\n",
    "\n",
    "# Loop melalui semua file dalam daftar\n",
    "for filename in csv_files:\n",
    "    file_path = os.path.join(data_dir, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_list.append(df)\n",
    "\n",
    "# Menggabungkan semua DataFrame menjadi satu\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Mengisi nilai data yang hilang dengan metode interpolasi\n",
    "combined_df.interpolate(method='linear', inplace=True)\n",
    "\n",
    "# Menyimpan DataFrame gabungan ke file CSV baru\n",
    "output_file = os.path.join(data_dir, 'gabungan.csv')\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Data gabungan telah disimpan di {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgZkbJLpK9UR"
   },
   "source": [
    "# **4. Exploratory Data Analysis (EDA)**\n",
    "\n",
    "Pada tahap ini, Anda akan melakukan **Exploratory Data Analysis (EDA)** untuk memahami karakteristik dataset. EDA bertujuan untuk:\n",
    "\n",
    "1. **Memahami Struktur Data**\n",
    "   - Tinjau jumlah baris dan kolom dalam dataset.  \n",
    "   - Tinjau jenis data di setiap kolom (numerikal atau kategorikal).\n",
    "\n",
    "2. **Menangani Data yang Hilang**  \n",
    "   - Identifikasi dan analisis data yang hilang (*missing values*). Tentukan langkah-langkah yang diperlukan untuk menangani data yang hilang, seperti pengisian atau penghapusan data tersebut.\n",
    "\n",
    "3. **Analisis Distribusi dan Korelasi**  \n",
    "   - Analisis distribusi variabel numerik dengan statistik deskriptif dan visualisasi seperti histogram atau boxplot.  \n",
    "   - Periksa hubungan antara variabel menggunakan matriks korelasi atau scatter plot.\n",
    "\n",
    "4. **Visualisasi Data**  \n",
    "   - Buat visualisasi dasar seperti grafik distribusi dan diagram batang untuk variabel kategorikal.  \n",
    "   - Gunakan heatmap atau pairplot untuk menganalisis korelasi antar variabel.\n",
    "\n",
    "Tujuan dari EDA adalah untuk memperoleh wawasan awal yang mendalam mengenai data dan menentukan langkah selanjutnya dalam analisis atau pemodelan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada tahap ini, Anda akan melakukan **Exploratory Data Analysis (EDA)** untuk memahami karakteristik dataset. EDA bertujuan untuk:\n",
    "\n",
    "## 1. Memahami Struktur Data\n",
    "### Penjelasan\n",
    "- Tinjau jumlah baris dan kolom dalam dataset.\n",
    "- Tinjau jenis data di setiap kolom (numerikal atau kategorikal).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKeejtvxM6X1"
   },
   "outputs": [],
   "source": [
    "air_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memahami Struktur Data\n",
    "def analyze_structure(df):\n",
    "    # Tinjau jumlah baris dan kolom dalam dataset\n",
    "    print(f\"Jumlah baris: {df.shape[0]}\")\n",
    "    print(f\"Jumlah kolom: {df.shape[1]}\")\n",
    "    \n",
    "    # Tinjau jenis data di setiap kolom\n",
    "    print(\"\\nJenis data di setiap kolom:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "    # Tinjau kolom numerikal dan kategorikal\n",
    "    numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    print(\"\\nKolom numerikal:\")\n",
    "    print(numerical_cols)\n",
    "    \n",
    "    print(\"\\nKolom kategorikal:\")\n",
    "    print(categorical_cols)\n",
    "\n",
    "# Contoh penggunaan fungsi\n",
    "analyze_structure(air_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah baris: 420768\n",
      "Jumlah kolom: 18\n",
      "No           int64\n",
      "year         int64\n",
      "month        int64\n",
      "day          int64\n",
      "hour         int64\n",
      "PM2.5      float64\n",
      "PM10       float64\n",
      "SO2        float64\n",
      "NO2        float64\n",
      "CO         float64\n",
      "O3         float64\n",
      "TEMP       float64\n",
      "PRES       float64\n",
      "DEWP       float64\n",
      "RAIN       float64\n",
      "wd          object\n",
      "WSPM       float64\n",
      "station     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Membaca dataset\n",
    "air_df = pd.read_csv('../projeck/data/gabungan.csv')\n",
    "\n",
    "# Menampilkan jumlah baris dan kolom\n",
    "print(f\"Jumlah baris: {air_df.shape[0]}\")\n",
    "print(f\"Jumlah kolom: {air_df.shape[1]}\")\n",
    "\n",
    "# Menampilkan jenis data di setiap kolom\n",
    "print(air_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Menangani Data yang Hilang\n",
    "\n",
    "### Identifikasi dan Analisis Data yang Hilang\n",
    "\n",
    "Langkah pertama dalam menangani data yang hilang adalah mengidentifikasi kolom-kolom yang memiliki nilai hilang dan menganalisis seberapa banyak data yang hilang. Kita dapat menggunakan visualisasi untuk mempermudah pemahaman mengenai distribusi data yang hilang.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Missing Values, Percentage]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Menghitung jumlah dan persentase data yang hilang di setiap kolom\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "# Membuat DataFrame untuk menampilkan data yang hilang\n",
    "missing_data = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "}).sort_values(by='Missing Values', ascending=False)\n",
    "\n",
    "# Menampilkan kolom yang memiliki data hilang\n",
    "print(missing_data[missing_data['Missing Values'] > 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9053/1627450267.py:2: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df.interpolate(method='linear', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Mengisi nilai data yang hilang dengan metode interpolasi\n",
    "df.interpolate(method='linear', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Missing Values, Percentage]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9053/4106493165.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['wd'].fillna(method='bfill', inplace=True)\n",
      "/tmp/ipykernel_9053/4106493165.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['wd'].fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Mengisi nilai yang hilang pada kolom 'wd' dengan metode backfill\n",
    "df['wd'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Menampilkan jumlah dan persentase data yang hilang setelah pengisian\n",
    "missing_values_after = df.isnull().sum()\n",
    "missing_percentage_after = (missing_values_after / len(df)) * 100\n",
    "\n",
    "missing_data_after = pd.DataFrame({\n",
    "    'Missing Values': missing_values_after,\n",
    "    'Percentage': missing_percentage_after\n",
    "}).sort_values(by='Missing Values', ascending=False)\n",
    "\n",
    "print(missing_data_after[missing_data_after['Missing Values'] > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpgHfgnSK3ip"
   },
   "source": [
    "# **5. Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COf8KUPXLg5r"
   },
   "source": [
    "Pada tahap ini, data preprocessing adalah langkah penting untuk memastikan kualitas data sebelum digunakan dalam model machine learning. Data mentah sering kali mengandung nilai kosong, duplikasi, atau rentang nilai yang tidak konsisten, yang dapat memengaruhi kinerja model. Oleh karena itu, proses ini bertujuan untuk membersihkan dan mempersiapkan data agar analisis berjalan optimal.\n",
    "\n",
    "Berikut adalah tahapan-tahapan yang perlu dilakukan, namun **tidak terbatas** pada:\n",
    "1. Menghapus atau Menangani Data Kosong (Missing Values)\n",
    "2. Menghapus Data Duplikat\n",
    "3. Normalisasi atau Standarisasi Fitur\n",
    "4. Deteksi dan Penanganan Outlier\n",
    "5. Encoding Data Kategorikal\n",
    "6. Binning (Pengelompokan Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WzBGjcbQM7N8"
   },
   "outputs": [],
   "source": [
    "#Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BR73dCnrLEiq"
   },
   "source": [
    "# **6. Pembangunan Model Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fkd_QHXWMBDr"
   },
   "source": [
    "## **a. Pembangunan Model Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kn6Y2qbqMVLP"
   },
   "source": [
    "Pada tahap ini, Anda membangun model clustering dengan memilih algoritma yang sesuai untuk mengelompokkan data berdasarkan kesamaan. Berikut adalah **rekomendasi** tahapannya.\n",
    "1. Pilih algoritma clustering yang sesuai.\n",
    "2. Latih model dengan data menggunakan algoritma tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgYvwWOzM93L"
   },
   "outputs": [],
   "source": [
    "#Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsGVwzPKMEvn"
   },
   "source": [
    "## **b. Evaluasi Model Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qk63ew39MeBf"
   },
   "source": [
    "Untuk menentukan jumlah cluster yang optimal dalam model clustering, Anda dapat menggunakan metode Elbow atau Silhouette Score.\n",
    "\n",
    "Metode ini membantu kita menemukan jumlah cluster yang memberikan pemisahan terbaik antar kelompok data, sehingga model yang dibangun dapat lebih efektif. Berikut adalah **rekomendasi** tahapannya.\n",
    "1. Gunakan Silhouette Score dan Elbow Method untuk menentukan jumlah cluster optimal.\n",
    "2. Hitung Silhouette Score sebagai ukuran kualitas cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrPkK_bvM-Ya"
   },
   "outputs": [],
   "source": [
    "#Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWZp5vKNQddd"
   },
   "source": [
    "## **c. Feature Selection (Opsional)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIHKgE07Q4c0"
   },
   "source": [
    "Silakan lakukan feature selection jika Anda membutuhkan optimasi model clustering. Jika Anda menerapkan proses ini, silakan lakukan pemodelan dan evaluasi kembali menggunakan kolom-kolom hasil feature selection. Terakhir, bandingkan hasil performa model sebelum dan sesudah menerapkan feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vbstha0PRUpI"
   },
   "outputs": [],
   "source": [
    "#Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nn01TKkLLRiF"
   },
   "source": [
    "## **d. Visualisasi Hasil Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gaz0fnhhMkRI"
   },
   "source": [
    "Setelah model clustering dilatih dan jumlah cluster optimal ditentukan, langkah selanjutnya adalah menampilkan hasil clustering melalui visualisasi.\n",
    "\n",
    "Berikut adalah **rekomendasi** tahapannya.\n",
    "1. Tampilkan hasil clustering dalam bentuk visualisasi, seperti grafik scatter plot atau 2D PCA projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lfOjVvfYM-4v"
   },
   "outputs": [],
   "source": [
    "#Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4eydPWJLH4I"
   },
   "source": [
    "## **e. Analisis dan Interpretasi Hasil Cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SENfLnfRMpC-"
   },
   "source": [
    "Setelah melakukan clustering, langkah selanjutnya adalah menganalisis karakteristik dari masing-masing cluster berdasarkan fitur yang tersedia.\n",
    "\n",
    "Berikut adalah **rekomendasi** tahapannya.\n",
    "1. Analisis karakteristik tiap cluster berdasarkan fitur yang tersedia (misalnya, distribusi nilai dalam cluster).\n",
    "2. Berikan interpretasi: Apakah hasil clustering sesuai dengan ekspektasi dan logika bisnis? Apakah ada pola tertentu yang bisa dimanfaatkan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFq0x-OzM_Wt"
   },
   "outputs": [],
   "source": [
    "#Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfgVMEBDS3KG"
   },
   "source": [
    "Tulis hasil interpretasinya di sini.\n",
    "1. Cluster 1:\n",
    "2. Cluster 2:\n",
    "3. Cluster 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaYP1fx5VgWO"
   },
   "source": [
    "# **7. Mengeksport Data**\n",
    "\n",
    "Simpan hasilnya ke dalam file CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fkbg_o80aRSH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
